#!/bin/bash

set -o errexit
set -o nounset
set -o pipefail
set -o monitor
set -o noglob

# the model name
MODEL="deepseek-r1:14b"
declare -r MODEL

# prompt file
PROMPT_FILE=${1:?Prompt file is not specified}
declare -r PROMPT_FILE

# load a prompt from the file
PROMPT_JSON=$(jq --raw-input --slurp --compact-output --raw-output 'tojson' "${PROMPT_FILE}")
declare -r PROMPT_JSON

# temporary file for the JSON request
REQUEST_FILE=$(mktemp)
declare -r REQUEST_FILE

# make a request file
cat > "${REQUEST_FILE}" <<EOF
{
  "model": "${MODEL}",
  "prompt": ${PROMPT_JSON},
  "stream": false,
  "options": {
    "temperature": 0.0
  }
}
EOF

# make a request to Ollama server
curl 'http://localhost:11434/api/generate' \
    --silent \
    --max-time 300 \
    --header "Content-Type: application/json" \
    --request POST \
    --data-binary "@${REQUEST_FILE}" \
  | jq '.' \
  > "${PROMPT_FILE}.response.json"

# extract only text
jq --raw-output '.response' "${PROMPT_FILE}.response.json" \
  > "${PROMPT_FILE}.response.txt"

# remove the temporary request file
rm "${REQUEST_FILE}"
